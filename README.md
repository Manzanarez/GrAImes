# GrAImes
Grading AI Microfiction Evaluation System

This Github repository contains the data analysed for the scientific paper "Introducing GrAImes: a literary quality evaluation protocol for AI generated microfictions", file "GrAImes_microfictions_evaluations.xlsx"

Abstract: Automated story writing has been a subject of study for over 60 years. While
there are mechanisms capable of generating consistent and coherent stories, and even those
that employ narratological theories or demonstrate a strong command of language, little
attention has been given to evaluating these texts in terms of their literary value, particularly
from an aesthetic perspective. In this paper, we address the challenge of evaluating literary
microfictions and argue that this task requires consideration of literary criteria across
various aspects of the text. To facilitate this, we present an evaluation protocol grounded
in literary theory, specifically drawing from the communication approach, to offer an
objective framework for assessing generated texts. Furthermore, we report the results of our
validation of the evaluation protocol (GrAImes), as answered by literary professionals. This
protocol will serve as a foundation for evaluating automatically generated microfictions
and assessing their literary value.

Keywords: evaluation; protocol; microfiction; literary
